# -- Cloudnative-pg cluster configuration
cluster:
  instances: 2
  annotations: {}
  affinity: {}

  # -- Select image to use
  # imageCatalogRef:
  #   apiGroup: postgresql.cnpg.io
  #   kind: ClusterImageCatalog
  #   name: postgresql-standard-trixie
  #   major: 16
  imageCatalogRef: {}

  # WARNING: Either use imageCatalogRef or specify the image directly
  # -- Image configuration
  image:
    name: ghcr.io/cloudnative-pg/postgresql:18-standard-trixie@sha256:d393376fb67a2df53bb09acae89b39b2742b77519b4bc59f337ca9dfb7455cb1

  storage:
    storageClass: openebs-hostpath
    size: 8Gi
  # -- Activate wal storage for high availability
  walStorage:
    storageClass: openebs-hostpath
    size: 1Gi

  # -- Enable external service to expose the primary instance
  externalService:
    enabled: false
    targetInstanceRole: primary

  # -- Postgresql configuration
  # https://cloudnative-pg.io/docs/1.28/postgresql_conf/
  postgresql:
    parameters:
      max_connections: "300"

    # -- Enable extension
    # shared_preload_libraries:
    #   - extension_name
    shared_preload_libraries: []

  # -- Admin superuser
  superuserSecret: superuser-secret
  enableSuperuserAccess: true

  # -- Define roles that will be created in the cluster at startup
  # roles:
  #   - name: a4-bitcoin-testnet
  #     ensure: present
  #     superuser: false
  #     login: true
  #     createdb: true
  #     passwordSecret:
  #       name: a4-bitcoin-testnet-cnpg
  roles: []

  # -- Bootstrap configuration for new cluster
  # bootstrap:
  #   initdb:
  #     database: app
  #     owner: app
  #     dataChecksums: true
  #     encoding: 'LATIN1'
  #     postInitSQL:
  #           - CREATE DATABASE angus
  #
  # -- Recover from backup
  # https://cloudnative-pg.io/docs/1.28/recovery/
  # bootstrap:
  #   recovery:
  #     source: origin
  bootstrap: {}

  # -- Resource requests and limits
  # resources:
  #   limits:
  #     cpu: "4"
  #     memory: 8Gi
  #   requests:
  #     cpu: "4"
  #     memory: 8Gi
  resources: {}

  # -- Monitoring configuration
  # https://cloudnative-pg.io/docs/1.28/monitoring/
  monitoring: {}

  # -- Create PodMonitor for Prometheus Operator
  podMonitor:
    enabled: false

  # -- Enable backup to object store for this cluster
  # https://cloudnative-pg.io/plugin-barman-cloud/docs/concepts/
  # plugins:
  #   - name: barman-cloud.cloudnative-pg.io
  #     isWALArchiver: true
  #     parameters:
  #       barmanObjectName: s3-storage
  plugins: []

  # -- Connect to an external cluster for recovery
  # https://cloudnative-pg.io/docs/1.28/recovery/
  # externalClusters:
  #   - name: origin
  #     plugin:
  #       name: barman-cloud.cloudnative-pg.io
  #       parameters:
  #         barmanObjectName: cluster-example-backup
  #         serverName: cluster-example
  externalClusters: {}

# -- Create db on cloudnative-pg
database:
  # -- Enable logical replication for each database. It will create publication/subscription for upgrading purposes.
  # -- https://cloudnative-pg.io/docs/1.28/logical_replication
  # -- https://www.postgresql.org/docs/current/logical-replication-subscription.html
  logicalReplication:
    enabled: false
    # Possible values: publisher, subscriber
    role: "publisher"
    # Specify external cluster name for subscriber role only
    # You must define externalClusterName in cluster.externalClusters
    externalClusterName: ""

  # -- Create db on cloudnative-pg
  # list:
  #   - name: database1
  #     owner: database1-owner
  #     secretName: database1-secret
  #     # Recovery job use pgcopydb to restore database. Make sure the image below has pgcopydb installed
  #     recovery:
  #       enabled: false
  #       imageName: ghcr.io/cloudnative-pg/postgresql:16.2-16
  #       dbSourceHost: <db-source-host>
  #       dbSourceSecretName: <db-source-secret-name>
  #     extensions:
  #       - name: extenstion_name
  #         ensure: present
  #     schemas:
  #       - name: datadog
  #         owner: datadog
  #         ensure: present
  list: []

# -- Object Store configuration
# objectStore:
#   enabled: true
#   name: s3-storage
#   spec:
#     configuration:
#       destinationPath: s3://backup
#       endpointURL: http://s3.minio.svc.cluster.local:9000
#       s3Credentials:
#       # Key should be named as ACCESS_KEY_ID and ACCESS_SECRET_KEY
#         accessKeyId:
#           name: s3-minio-secret
#           key: MINIO_ROOT_USER
#         secretAccessKey:
#           name: s3-minio-secret
#           key: MINIO_ROOT_PASSWORD
#       wal:
#         compression: gzip
#     retentionPolicy: 30d
objectStore:
  enabled: false
